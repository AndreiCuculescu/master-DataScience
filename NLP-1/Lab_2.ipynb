{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# The Stanford POS Tagger\n"
      ],
      "metadata": {
        "id": "TOiBlh5oa6ze"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Web app version: http://nlp.stanford.edu:8080/parser/ ; https://corenlp.run/\n",
        "\n",
        "Newer version of the NLTK interface, requires running a java server locally: https://github.com/nltk/nltk/wiki/Stanford-CoreNLP-API-in-NLTK\n"
      ],
      "metadata": {
        "id": "cfHeXLEUgIKn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Downloading the tagger and models"
      ],
      "metadata": {
        "id": "MOXWLw-SbCpQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download and uzip the model. You can do the same thing on your own computer to be able to use it locally."
      ],
      "metadata": {
        "id": "rmImjTN1bZMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "!wget 'https://nlp.stanford.edu/software/stanford-tagger-4.2.0.zip'\n",
        "!unzip './stanford-tagger-4.2.0.zip'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nYqHkCnbF0o",
        "outputId": "4b66d97b-533d-454e-8d12-3c6597fb01f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-13 10:06:02--  https://nlp.stanford.edu/software/stanford-tagger-4.2.0.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: https://downloads.cs.stanford.edu/nlp/software/stanford-tagger-4.2.0.zip [following]\n",
            "--2023-03-13 10:06:02--  https://downloads.cs.stanford.edu/nlp/software/stanford-tagger-4.2.0.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 78034596 (74M) [application/zip]\n",
            "Saving to: ‘stanford-tagger-4.2.0.zip’\n",
            "\n",
            "stanford-tagger-4.2 100%[===================>]  74.42M  5.12MB/s    in 11s     \n",
            "\n",
            "2023-03-13 10:06:14 (6.97 MB/s) - ‘stanford-tagger-4.2.0.zip’ saved [78034596/78034596]\n",
            "\n",
            "Archive:  ./stanford-tagger-4.2.0.zip\n",
            "   creating: stanford-postagger-full-2020-11-17/\n",
            "  inflating: stanford-postagger-full-2020-11-17/stanford-postagger-gui.sh  \n",
            "  inflating: stanford-postagger-full-2020-11-17/sample-input.txt  \n",
            "  inflating: stanford-postagger-full-2020-11-17/stanford-postagger.jar  \n",
            "   creating: stanford-postagger-full-2020-11-17/data/\n",
            "  inflating: stanford-postagger-full-2020-11-17/data/enclitic-inflections.data  \n",
            "  inflating: stanford-postagger-full-2020-11-17/stanford-postagger-4.2.0-javadoc.jar  \n",
            "  inflating: stanford-postagger-full-2020-11-17/README.txt  \n",
            "  inflating: stanford-postagger-full-2020-11-17/stanford-postagger-4.2.0.jar  \n",
            "  inflating: stanford-postagger-full-2020-11-17/stanford-postagger.sh  \n",
            "   creating: stanford-postagger-full-2020-11-17/models/\n",
            "  inflating: stanford-postagger-full-2020-11-17/models/english-left3words-distsim.tagger.props  \n",
            "  inflating: stanford-postagger-full-2020-11-17/models/spanish-ud.tagger.props  \n",
            "  inflating: stanford-postagger-full-2020-11-17/models/english-caseless-left3words-distsim.tagger.props  \n",
            "  inflating: stanford-postagger-full-2020-11-17/models/spanish-ud.tagger  \n",
            "  inflating: stanford-postagger-full-2020-11-17/models/arabic-train.tagger  \n",
            "  inflating: stanford-postagger-full-2020-11-17/models/english-left3words-distsim.tagger  \n",
            "  inflating: stanford-postagger-full-2020-11-17/models/english-bidirectional-distsim.tagger.props  \n",
            "  inflating: stanford-postagger-full-2020-11-17/models/arabic.tagger  \n",
            "  inflating: stanford-postagger-full-2020-11-17/models/chinese-distsim.tagger  \n",
            "  inflating: stanford-postagger-full-2020-11-17/models/german-ud.tagger.props  \n",
            "  inflating: stanford-postagger-full-2020-11-17/models/french-ud.tagger.props  \n",
            "  inflating: stanford-postagger-full-2020-11-17/models/arabic.tagger.props  \n",
            "  inflating: stanford-postagger-full-2020-11-17/models/english-caseless-left3words-distsim.tagger  \n",
            "  inflating: stanford-postagger-full-2020-11-17/models/french-ud.tagger  \n",
            "  inflating: stanford-postagger-full-2020-11-17/models/english-bidirectional-distsim.tagger  \n",
            "  inflating: stanford-postagger-full-2020-11-17/models/chinese-nodistsim.tagger  \n",
            "  inflating: stanford-postagger-full-2020-11-17/models/chinese-distsim.tagger.props  \n",
            "  inflating: stanford-postagger-full-2020-11-17/models/german-ud.tagger  \n",
            "  inflating: stanford-postagger-full-2020-11-17/models/README-Models.txt  \n",
            "  inflating: stanford-postagger-full-2020-11-17/models/chinese-nodistsim.tagger.props  \n",
            "  inflating: stanford-postagger-full-2020-11-17/models/arabic-train.tagger.props  \n",
            "  inflating: stanford-postagger-full-2020-11-17/stanford-postagger-gui.bat  \n",
            "  inflating: stanford-postagger-full-2020-11-17/build.xml  \n",
            "  inflating: stanford-postagger-full-2020-11-17/TaggerDemo2.java  \n",
            "  inflating: stanford-postagger-full-2020-11-17/sample-output.txt  \n",
            "  inflating: stanford-postagger-full-2020-11-17/stanford-postagger.bat  \n",
            "  inflating: stanford-postagger-full-2020-11-17/TaggerDemo.java  \n",
            "  inflating: stanford-postagger-full-2020-11-17/stanford-postagger-4.2.0-sources.jar  \n",
            "  inflating: stanford-postagger-full-2020-11-17/LICENSE.txt  \n",
            "CPU times: user 167 ms, sys: 47.3 ms, total: 214 ms\n",
            "Wall time: 13.6 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting up and using the tagger with NLTK"
      ],
      "metadata": {
        "id": "gT_y9OzBbGwg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path='./stanford-postagger-full-2020-11-17/models/english-bidirectional-distsim.tagger'\n",
        "jar_tagger_path='./stanford-postagger-full-2020-11-17/stanford-postagger-4.2.0.jar'"
      ],
      "metadata": {
        "id": "xUr6gPwJFKuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6e8EcS6qqVL5"
      },
      "outputs": [],
      "source": [
        "from nltk.tag.stanford import StanfordPOSTagger # -- deprecated?\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze | grep nltk # needs nltk >= 3.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kRn3vy0SYlB",
        "outputId": "e1e11347-efff-429f-aeeb-5f93d8098540"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nltk==3.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tagger=StanfordPOSTagger(model_path, jar_tagger_path)\n"
      ],
      "metadata": {
        "id": "t6dDj5bcErgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNGYvc7GWfrX",
        "outputId": "fedcfdf6-67f2-4410-9b0a-e57ce736ce3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tagger.tag(nltk.word_tokenize(\"I am eating a lot of candy.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ovqmsl_yE1ac",
        "outputId": "26f7d738-5a5b-4cad-aa2e-b49123530f92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('I', 'PRP'),\n",
              " ('am', 'VBP'),\n",
              " ('eating', 'VBG'),\n",
              " ('a', 'DT'),\n",
              " ('lot', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('candy', 'NN'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tagger.tag(nltk.word_tokenize(\"Time flies like an arrow.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoauGuMcmT0C",
        "outputId": "b00a8c26-9fb2-43f9-c34c-4a87e0131a77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Time', 'NNP'),\n",
              " ('flies', 'VBZ'),\n",
              " ('like', 'IN'),\n",
              " ('an', 'DT'),\n",
              " ('arrow', 'NN'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tagger.tag(nltk.word_tokenize(\"Fruit flies like a banana.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9VN5EdHWQzQ",
        "outputId": "76d21901-811e-4a9c-912e-3776a8e52cc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Fruit', 'NNP'),\n",
              " ('flies', 'VBZ'),\n",
              " ('like', 'IN'),\n",
              " ('a', 'DT'),\n",
              " ('banana', 'NN'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tagger.tag(nltk.word_tokenize(\"I don't like fruit flies like a banana.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TD98Iz1EmUE2",
        "outputId": "4fb877d6-686e-46e7-c1d4-7f5644081162"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('I', 'PRP'),\n",
              " ('do', 'VBP'),\n",
              " (\"n't\", 'RB'),\n",
              " ('like', 'VB'),\n",
              " ('fruit', 'NN'),\n",
              " ('flies', 'NNS'),\n",
              " ('like', 'IN'),\n",
              " ('a', 'DT'),\n",
              " ('banana', 'NN'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tagger.tag(nltk.word_tokenize(\"I am eating a lot of candy.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4sjjsmG4Jc7",
        "outputId": "e41d020e-bd05-4679-b49d-9304cd66b47d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('I', 'PRP'),\n",
              " ('am', 'VBP'),\n",
              " ('eating', 'VBG'),\n",
              " ('a', 'DT'),\n",
              " ('lot', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('candy', 'NN'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "st = PorterStemmer()\n",
        "tagger.tag([st.stem(t)\n",
        "      for t in nltk.word_tokenize(\"I am eating a lot of candy.\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjcJgsNAFDl6",
        "outputId": "c4f7de66-869a-48bc-e19f-fc72e99d936e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('i', 'PRP'),\n",
              " ('am', 'VBP'),\n",
              " ('eat', 'VB'),\n",
              " ('a', 'DT'),\n",
              " ('lot', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('candi', 'NN'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using averaged_perceptron_tagger in NLTK"
      ],
      "metadata": {
        "id": "eOhBNvOHjbgA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oiS8XGnajjP",
        "outputId": "cccc6fbf-2181-40ed-dd0f-c2318710e828"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.pos_tag(nltk.word_tokenize(\"I am eating a lot of candy.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trUEM4Y3jj1t",
        "outputId": "70617b80-3b83-4064-ef8c-32c9fc5e7e41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('I', 'PRP'),\n",
              " ('am', 'VBP'),\n",
              " ('eating', 'VBG'),\n",
              " ('a', 'DT'),\n",
              " ('lot', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('candy', 'NN'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.pos_tag(nltk.word_tokenize(\"Time flies like an arrow.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmrSdotFjrpk",
        "outputId": "62ba0c95-99d2-46ac-9f75-b48c9d22dcb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Time', 'NNP'),\n",
              " ('flies', 'NNS'),\n",
              " ('like', 'IN'),\n",
              " ('an', 'DT'),\n",
              " ('arrow', 'NN'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.pos_tag(nltk.word_tokenize(\"Fruit flies like a banana.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "213h9xIbmMcF",
        "outputId": "1b71924a-1103-4b44-abae-6cec67d87a79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Fruit', 'NNP'),\n",
              " ('flies', 'VBZ'),\n",
              " ('like', 'IN'),\n",
              " ('a', 'DT'),\n",
              " ('banana', 'NN'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Understanding the tags"
      ],
      "metadata": {
        "id": "UPjryCPmcUhA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('tagsets')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cvzHwm3cWOg",
        "outputId": "22235af3-de03-4243-b364-6134ee46032b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]   Unzipping help/tagsets.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.help.upenn_tagset('NNP')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmE9xp0ocdT4",
        "outputId": "d17a468c-9f1a-48fa-d731-b98e6449340b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NNP: noun, proper, singular\n",
            "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
            "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
            "    Shannon A.K.C. Meltex Liverpool ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e1aZEtcncfM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tagged corpora"
      ],
      "metadata": {
        "id": "BdLxIkm7-nER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('brown')\n",
        "nltk.corpus.brown.tagged_words()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyMcw22io47Y",
        "outputId": "746251ce-b4cf-40a5-eaf6-4835cbaafece"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('The', 'AT'), ('Fulton', 'NP-TL'), ...]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(nltk.corpus.brown.tagged_sents(categories='news'))[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDispBNWHx9A",
        "outputId": "af5e18d1-4aab-4bfa-fabf-ab79f1f43400"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('The', 'AT'),\n",
              "  ('Fulton', 'NP-TL'),\n",
              "  ('County', 'NN-TL'),\n",
              "  ('Grand', 'JJ-TL'),\n",
              "  ('Jury', 'NN-TL'),\n",
              "  ('said', 'VBD'),\n",
              "  ('Friday', 'NR'),\n",
              "  ('an', 'AT'),\n",
              "  ('investigation', 'NN'),\n",
              "  ('of', 'IN'),\n",
              "  (\"Atlanta's\", 'NP$'),\n",
              "  ('recent', 'JJ'),\n",
              "  ('primary', 'NN'),\n",
              "  ('election', 'NN'),\n",
              "  ('produced', 'VBD'),\n",
              "  ('``', '``'),\n",
              "  ('no', 'AT'),\n",
              "  ('evidence', 'NN'),\n",
              "  (\"''\", \"''\"),\n",
              "  ('that', 'CS'),\n",
              "  ('any', 'DTI'),\n",
              "  ('irregularities', 'NNS'),\n",
              "  ('took', 'VBD'),\n",
              "  ('place', 'NN'),\n",
              "  ('.', '.')],\n",
              " [('The', 'AT'),\n",
              "  ('jury', 'NN'),\n",
              "  ('further', 'RBR'),\n",
              "  ('said', 'VBD'),\n",
              "  ('in', 'IN'),\n",
              "  ('term-end', 'NN'),\n",
              "  ('presentments', 'NNS'),\n",
              "  ('that', 'CS'),\n",
              "  ('the', 'AT'),\n",
              "  ('City', 'NN-TL'),\n",
              "  ('Executive', 'JJ-TL'),\n",
              "  ('Committee', 'NN-TL'),\n",
              "  (',', ','),\n",
              "  ('which', 'WDT'),\n",
              "  ('had', 'HVD'),\n",
              "  ('over-all', 'JJ'),\n",
              "  ('charge', 'NN'),\n",
              "  ('of', 'IN'),\n",
              "  ('the', 'AT'),\n",
              "  ('election', 'NN'),\n",
              "  (',', ','),\n",
              "  ('``', '``'),\n",
              "  ('deserves', 'VBZ'),\n",
              "  ('the', 'AT'),\n",
              "  ('praise', 'NN'),\n",
              "  ('and', 'CC'),\n",
              "  ('thanks', 'NNS'),\n",
              "  ('of', 'IN'),\n",
              "  ('the', 'AT'),\n",
              "  ('City', 'NN-TL'),\n",
              "  ('of', 'IN-TL'),\n",
              "  ('Atlanta', 'NP-TL'),\n",
              "  (\"''\", \"''\"),\n",
              "  ('for', 'IN'),\n",
              "  ('the', 'AT'),\n",
              "  ('manner', 'NN'),\n",
              "  ('in', 'IN'),\n",
              "  ('which', 'WDT'),\n",
              "  ('the', 'AT'),\n",
              "  ('election', 'NN'),\n",
              "  ('was', 'BEDZ'),\n",
              "  ('conducted', 'VBN'),\n",
              "  ('.', '.')]]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Penn Treebank Corpus"
      ],
      "metadata": {
        "id": "f87x_HaCAc5o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "References:\n",
        "\n",
        "Paper with Penn Treebank description: https://www.researchgate.net/publication/2873803_The_Penn_Treebank_An_overview\n",
        "\n",
        "List of explanations for tag acronyms: https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n"
      ],
      "metadata": {
        "id": "NUHBOwuFI1-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('treebank')\n",
        "len(list(nltk.corpus.treebank.tagged_words()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzKpPn3b-t59",
        "outputId": "ade47c2c-60d6-4318-f4c8-f64546c042ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100676"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.corpus.treebank.tagged_words()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jj6m7U-Ag5v",
        "outputId": "dd49fc96-85e0-45ee-fe53-03cad5b4ddcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ...]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Other tools, POS Tagging performance & comparison: https://aclweb.org/aclwiki/index.php?title=POS_Tagging_(State_of_the_art)"
      ],
      "metadata": {
        "id": "FFZ0yM74MT8e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Syntactic Parsing"
      ],
      "metadata": {
        "id": "BVvUf_bfjv7V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stanford Parser"
      ],
      "metadata": {
        "id": "USY05F9NHDfs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can try the usage below locally: (needs java)"
      ],
      "metadata": {
        "id": "1wW5TEazbjwV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget 'https://nlp.stanford.edu/software/stanford-parser-4.2.0.zip'\n",
        "!unzip 'stanford-parser-4.2.0.zip'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWCNPBqTnEej",
        "outputId": "7f5b34cd-74ef-4372-adf7-9b31fbeae4fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-21 11:48:00--  https://nlp.stanford.edu/software/stanford-parser-4.2.0.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: https://downloads.cs.stanford.edu/nlp/software/stanford-parser-4.2.0.zip [following]\n",
            "--2023-03-21 11:48:00--  https://downloads.cs.stanford.edu/nlp/software/stanford-parser-4.2.0.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 182285548 (174M) [application/zip]\n",
            "Saving to: ‘stanford-parser-4.2.0.zip’\n",
            "\n",
            "stanford-parser-4.2 100%[===================>] 173.84M  5.08MB/s    in 30s     \n",
            "\n",
            "2023-03-21 11:48:31 (5.73 MB/s) - ‘stanford-parser-4.2.0.zip’ saved [182285548/182285548]\n",
            "\n",
            "Archive:  stanford-parser-4.2.0.zip\n",
            "   creating: stanford-parser-full-2020-11-17/\n",
            "  inflating: stanford-parser-full-2020-11-17/ejml-simple-0.38.jar  \n",
            "  inflating: stanford-parser-full-2020-11-17/StanfordDependenciesManual.pdf  \n",
            "  inflating: stanford-parser-full-2020-11-17/Makefile  \n",
            "  inflating: stanford-parser-full-2020-11-17/ShiftReduceDemo.java  \n",
            "  inflating: stanford-parser-full-2020-11-17/slf4j-api-1.7.12-sources.jar  \n",
            "  inflating: stanford-parser-full-2020-11-17/ejml-core-0.38.jar  \n",
            "  inflating: stanford-parser-full-2020-11-17/build.xml  \n",
            "  inflating: stanford-parser-full-2020-11-17/lexparser-gui.sh  \n",
            "   creating: stanford-parser-full-2020-11-17/data/\n",
            " extracting: stanford-parser-full-2020-11-17/data/chinese-onesent-unseg-gb18030.txt  \n",
            " extracting: stanford-parser-full-2020-11-17/data/arabic-onesent-utf8.txt  \n",
            "  inflating: stanford-parser-full-2020-11-17/data/chinese-onesent-unseg-utf8.txt  \n",
            "  inflating: stanford-parser-full-2020-11-17/data/testsent.txt  \n",
            "  inflating: stanford-parser-full-2020-11-17/data/pos-sentences.txt  \n",
            " extracting: stanford-parser-full-2020-11-17/data/chinese-onesent-utf8.txt  \n",
            " extracting: stanford-parser-full-2020-11-17/data/chinese-onesent-gb18030.txt  \n",
            " extracting: stanford-parser-full-2020-11-17/data/english-onesent.txt  \n",
            " extracting: stanford-parser-full-2020-11-17/data/german-onesent.txt  \n",
            "  inflating: stanford-parser-full-2020-11-17/data/french-onesent.txt  \n",
            "  inflating: stanford-parser-full-2020-11-17/LICENSE.txt  \n",
            "  inflating: stanford-parser-full-2020-11-17/stanford-parser-4.2.0-sources.jar  \n",
            "  inflating: stanford-parser-full-2020-11-17/lexparser-gui.command  \n",
            "  inflating: stanford-parser-full-2020-11-17/README_dependencies.txt  \n",
            "  inflating: stanford-parser-full-2020-11-17/ejml-ddense-0.38.jar  \n",
            "   creating: stanford-parser-full-2020-11-17/conf/\n",
            "  inflating: stanford-parser-full-2020-11-17/conf/ftb-latest.conf  \n",
            "  inflating: stanford-parser-full-2020-11-17/conf/atb-latest.conf  \n",
            "  inflating: stanford-parser-full-2020-11-17/ejml-ddense-0.39-sources.jar  \n",
            "  inflating: stanford-parser-full-2020-11-17/ejml-simple-0.39-sources.jar  \n",
            "  inflating: stanford-parser-full-2020-11-17/README.txt  \n",
            "  inflating: stanford-parser-full-2020-11-17/slf4j-simple.jar  \n",
            "  inflating: stanford-parser-full-2020-11-17/lexparser-lang-train-test.sh  \n",
            "  inflating: stanford-parser-full-2020-11-17/stanford-parser-4.2.0-models.jar  \n",
            "  inflating: stanford-parser-full-2020-11-17/stanford-parser-4.2.0-javadoc.jar  \n",
            "  inflating: stanford-parser-full-2020-11-17/lexparser.sh  \n",
            "  inflating: stanford-parser-full-2020-11-17/lexparser-lang.sh  \n",
            "  inflating: stanford-parser-full-2020-11-17/lexparser.bat  \n",
            "  inflating: stanford-parser-full-2020-11-17/ParserDemo2.java  \n",
            "  inflating: stanford-parser-full-2020-11-17/pom.xml  \n",
            "  inflating: stanford-parser-full-2020-11-17/ejml-core-0.39-sources.jar  \n",
            "  inflating: stanford-parser-full-2020-11-17/stanford-parser.jar  \n",
            "  inflating: stanford-parser-full-2020-11-17/DependencyParserDemo.java  \n",
            "   creating: stanford-parser-full-2020-11-17/bin/\n",
            "  inflating: stanford-parser-full-2020-11-17/bin/makeSerialized.csh  \n",
            "  inflating: stanford-parser-full-2020-11-17/bin/run-tb-preproc  \n",
            "  inflating: stanford-parser-full-2020-11-17/slf4j-api.jar  \n",
            "  inflating: stanford-parser-full-2020-11-17/ParserDemo.java  \n",
            "  inflating: stanford-parser-full-2020-11-17/lexparser_lang.def  \n",
            "  inflating: stanford-parser-full-2020-11-17/lexparser-gui.bat  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget 'https://nlp.stanford.edu/software/stanford-corenlp-4.2.0-models-english.jar'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YSxVuhnoFCQ",
        "outputId": "10dc47b2-0109-438c-c992-35b649b7d82f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-13 10:32:19--  https://nlp.stanford.edu/software/stanford-corenlp-4.2.0-models-english.jar\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: https://downloads.cs.stanford.edu/nlp/software/stanford-corenlp-4.2.0-models-english.jar [following]\n",
            "--2023-03-13 10:32:19--  https://downloads.cs.stanford.edu/nlp/software/stanford-corenlp-4.2.0-models-english.jar\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 669395561 (638M) [application/java-archive]\n",
            "Saving to: ‘stanford-corenlp-4.2.0-models-english.jar’\n",
            "\n",
            "stanford-corenlp-4. 100%[===================>] 638.38M  5.02MB/s    in 2m 2s   \n",
            "\n",
            "2023-03-13 10:34:22 (5.22 MB/s) - ‘stanford-corenlp-4.2.0-models-english.jar’ saved [669395561/669395561]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from nltk.parse.stanford import StanfordParser\n"
      ],
      "metadata": {
        "id": "mRHcRHDgj0Sq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['JAVAHOME'] = \"/usr/bin/java\"\n",
        "os.environ['STANFORD_PARSER'] = '/content/stanford-parser-full-2020-11-17/stanford-parser.jar'\n",
        "os.environ['STANFORD_MODELS'] = '/content/stanford-parser-full-2020-11-17/stanford-parser-4.2.0-models.jar'\n"
      ],
      "metadata": {
        "id": "vi-uBl6yk3HV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "parser = StanfordParser(model_path=\"/content/stanford-corenlp-4.2.0-models-english.jar\")\n",
        "propozitii = parser.raw_parse_sents((\"I like to go to school.\", \"The cat is running through the room.\",\"Where are you?\"))\n",
        "for prop in propozitii:\n",
        "    print(list(prop))"
      ],
      "metadata": {
        "id": "k-4RL7YelPyW",
        "outputId": "3e8fee95-ddf2-4b0c-811b-64340e379b72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 831
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-dd9aad16e19a>:1: DeprecationWarning: The StanfordParser will be deprecated\n",
            "Please use \u001b[91mnltk.parse.corenlp.CoreNLPParser\u001b[0m instead.\n",
            "  parser = StanfordParser(model_path=\"/content/stanford-corenlp-4.2.0-models-english.jar\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[main] ERROR edu.stanford.nlp.parser.lexparser.LexicalizedParser - java.io.IOException: Unable to open \"/content/stanford-corenlp-4.2.0-models-english.jar\" as class path, filename or URL\n",
            "  edu.stanford.nlp.io.IOUtils.getInputStreamFromURLOrClasspathOrFileSystem(IOUtils.java:501)\n",
            "  edu.stanford.nlp.io.IOUtils.readStreamFromString(IOUtils.java:402)\n",
            "  edu.stanford.nlp.parser.lexparser.LexicalizedParser.getParserFromSerializedFile(LexicalizedParser.java:567)\n",
            "  edu.stanford.nlp.parser.lexparser.LexicalizedParser.getParserFromFile(LexicalizedParser.java:373)\n",
            "  edu.stanford.nlp.parser.lexparser.LexicalizedParser.loadModel(LexicalizedParser.java:183)\n",
            "  edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(LexicalizedParser.java:1373)\n",
            "java.io.IOException: Unable to open \"/content/stanford-corenlp-4.2.0-models-english.jar\" as class path, filename or URL\n",
            "\tat edu.stanford.nlp.io.IOUtils.getInputStreamFromURLOrClasspathOrFileSystem(IOUtils.java:501)\n",
            "\tat edu.stanford.nlp.io.IOUtils.readerFromString(IOUtils.java:634)\n",
            "\tat edu.stanford.nlp.parser.lexparser.LexicalizedParser.getParserFromTextFile(LexicalizedParser.java:510)\n",
            "\tat edu.stanford.nlp.parser.lexparser.LexicalizedParser.getParserFromFile(LexicalizedParser.java:375)\n",
            "\tat edu.stanford.nlp.parser.lexparser.LexicalizedParser.loadModel(LexicalizedParser.java:183)\n",
            "\tat edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(LexicalizedParser.java:1373)\n",
            "Exception in thread \"main\" java.lang.NullPointerException\n",
            "\tat edu.stanford.nlp.parser.lexparser.LexicalizedParser.loadModel(LexicalizedParser.java:185)\n",
            "\tat edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(LexicalizedParser.java:1373)\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-dd9aad16e19a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStanfordParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/stanford-corenlp-4.2.0-models-english.jar\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpropozitii\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_parse_sents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"I like to go to school.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"The cat is running through the room.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Where are you?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mprop\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpropozitii\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/nltk/parse/stanford.py\u001b[0m in \u001b[0;36mraw_parse_sents\u001b[0;34m(self, sentences, verbose)\u001b[0m\n\u001b[1;32m    171\u001b[0m         ]\n\u001b[1;32m    172\u001b[0m         return self._parse_trees_output(\n\u001b[0;32m--> 173\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         )\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/nltk/parse/stanford.py\u001b[0m in \u001b[0;36m_execute\u001b[0;34m(self, cmd, input_, verbose)\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m                 \u001b[0mcmd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m                 stdout, stderr = java(\n\u001b[0m\u001b[1;32m    259\u001b[0m                     \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasspath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_classpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/nltk/internals.py\u001b[0m in \u001b[0;36mjava\u001b[0;34m(cmd, classpath, stdin, stdout, stderr, blocking)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_decode_stdoutdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Java command failed : \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Java command failed : ['/usr/bin/java', '-mx4g', '-cp', '/content/stanford-parser-full-2020-11-17/stanford-parser-4.2.0-models.jar:/content/stanford-parser-full-2020-11-17/ejml-ddense-0.38.jar:/content/stanford-parser-full-2020-11-17/slf4j-api.jar:/content/stanford-parser-full-2020-11-17/stanford-parser-4.2.0-sources.jar:/content/stanford-parser-full-2020-11-17/stanford-parser-4.2.0-javadoc.jar:/content/stanford-parser-full-2020-11-17/slf4j-api-1.7.12-sources.jar:/content/stanford-parser-full-2020-11-17/ejml-ddense-0.39-sources.jar:/content/stanford-parser-full-2020-11-17/stanford-parser-4.2.0-models.jar:/content/stanford-parser-full-2020-11-17/ejml-core-0.39-sources.jar:/content/stanford-parser-full-2020-11-17/ejml-core-0.38.jar:/content/stanford-parser-full-2020-11-17/ejml-simple-0.38.jar:/content/stanford-parser-full-2020-11-17/ejml-simple-0.39-sources.jar:/content/stanford-parser-full-2020-11-17/stanford-parser.jar:/content/stanford-parser-full-2020-11-17/slf4j-simple.jar', 'edu.stanford.nlp.parser.lexparser.LexicalizedParser', '-model', '/content/stanford-corenlp-4.2.0-models-english.jar', '-sentences', 'newline', '-outputFormat', 'penn', '-encoding', 'utf8', '/tmp/tmp00iv9fsn']"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Alternatively\n"
      ],
      "metadata": {
        "id": "j5nUR1Y3HHpk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget 'https://nlp.stanford.edu/software/stanford-corenlp-4.5.3.zip'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcKZ4wgPAk_n",
        "outputId": "f9d5d464-f7e3-4732-89c5-fd416020b511"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-21 11:51:36--  https://nlp.stanford.edu/software/stanford-corenlp-4.5.3.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: https://downloads.cs.stanford.edu/nlp/software/stanford-corenlp-4.5.3.zip [following]\n",
            "--2023-03-21 11:51:36--  https://downloads.cs.stanford.edu/nlp/software/stanford-corenlp-4.5.3.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 505406322 (482M) [application/zip]\n",
            "Saving to: ‘stanford-corenlp-4.5.3.zip’\n",
            "\n",
            "stanford-corenlp-4. 100%[===================>] 481.99M  5.08MB/s    in 93s     \n",
            "\n",
            "2023-03-21 11:53:09 (5.21 MB/s) - ‘stanford-corenlp-4.5.3.zip’ saved [505406322/505406322]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip 'stanford-corenlp-4.5.3.zip'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dy8pBJCbA9iF",
        "outputId": "f4884b8a-f47b-4171-93ce-52d35efc71ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  stanford-corenlp-4.5.3.zip\n",
            "   creating: stanford-corenlp-4.5.3/\n",
            "  inflating: stanford-corenlp-4.5.3/CoreNLP-to-HTML.xsl  \n",
            "  inflating: stanford-corenlp-4.5.3/jollyday-0.4.9-sources.jar  \n",
            "  inflating: stanford-corenlp-4.5.3/javax.activation-api-1.2.0.jar  \n",
            "  inflating: stanford-corenlp-4.5.3/javax.json.jar  \n",
            "  inflating: stanford-corenlp-4.5.3/ejml-ddense-0.39.jar  \n",
            "  inflating: stanford-corenlp-4.5.3/input.txt  \n",
            "  inflating: stanford-corenlp-4.5.3/istack-commons-runtime-3.0.7.jar  \n",
            "  inflating: stanford-corenlp-4.5.3/README.txt  \n",
            "  inflating: stanford-corenlp-4.5.3/stanford-corenlp-4.5.3-models.jar  \n",
            "  inflating: stanford-corenlp-4.5.3/ejml-core-0.39-sources.jar  \n",
            "  inflating: stanford-corenlp-4.5.3/ShiftReduceDemo.java  \n",
            "  inflating: stanford-corenlp-4.5.3/xom.jar  \n",
            "  inflating: stanford-corenlp-4.5.3/slf4j-simple.jar  \n",
            "  inflating: stanford-corenlp-4.5.3/jollyday.jar  \n",
            "  inflating: stanford-corenlp-4.5.3/pom-java-17.xml  \n",
            "  inflating: stanford-corenlp-4.5.3/ejml-simple-0.39.jar  \n",
            "  inflating: stanford-corenlp-4.5.3/input.txt.out  \n",
            "  inflating: stanford-corenlp-4.5.3/SemgrexDemo.java  \n",
            "  inflating: stanford-corenlp-4.5.3/build.xml  \n",
            "   creating: stanford-corenlp-4.5.3/tokensregex/\n",
            "  inflating: stanford-corenlp-4.5.3/tokensregex/retokenize.txt  \n",
            "  inflating: stanford-corenlp-4.5.3/tokensregex/color.properties  \n",
            "  inflating: stanford-corenlp-4.5.3/tokensregex/color.input.txt  \n",
            "  inflating: stanford-corenlp-4.5.3/tokensregex/color.rules.txt  \n",
            "  inflating: stanford-corenlp-4.5.3/sample-project-pom.xml  \n",
            "  inflating: stanford-corenlp-4.5.3/corenlp.sh  \n",
            "  inflating: stanford-corenlp-4.5.3/pom-java-11.xml  \n",
            "  inflating: stanford-corenlp-4.5.3/stanford-corenlp-4.5.3-javadoc.jar  \n",
            "  inflating: stanford-corenlp-4.5.3/protobuf-java-3.19.6.jar  \n",
            "  inflating: stanford-corenlp-4.5.3/RESOURCE-LICENSES  \n",
            "  inflating: stanford-corenlp-4.5.3/StanfordDependenciesManual.pdf  \n",
            "   creating: stanford-corenlp-4.5.3/patterns/\n",
            " extracting: stanford-corenlp-4.5.3/patterns/places.txt  \n",
            " extracting: stanford-corenlp-4.5.3/patterns/otherpeople.txt  \n",
            " extracting: stanford-corenlp-4.5.3/patterns/goldplaces.txt  \n",
            "  inflating: stanford-corenlp-4.5.3/patterns/stopwords.txt  \n",
            "  inflating: stanford-corenlp-4.5.3/patterns/names.txt  \n",
            "  inflating: stanford-corenlp-4.5.3/patterns/goldnames.txt  \n",
            "  inflating: stanford-corenlp-4.5.3/patterns/example.properties  \n",
            "  inflating: stanford-corenlp-4.5.3/patterns/presidents.txt  \n",
            "  inflating: stanford-corenlp-4.5.3/javax.activation-api-1.2.0-sources.jar  \n",
            "  inflating: stanford-corenlp-4.5.3/ejml-core-0.39.jar  \n",
            "  inflating: stanford-corenlp-4.5.3/LIBRARY-LICENSES  \n",
            "  inflating: stanford-corenlp-4.5.3/stanford-corenlp-4.5.3.jar  \n",
            "   creating: stanford-corenlp-4.5.3/sutime/\n",
            "  inflating: stanford-corenlp-4.5.3/sutime/spanish.sutime.txt  \n",
            "  inflating: stanford-corenlp-4.5.3/sutime/english.sutime.txt  \n",
            "  inflating: stanford-corenlp-4.5.3/sutime/defs.sutime.txt  \n",
            "  inflating: stanford-corenlp-4.5.3/sutime/english.holidays.sutime.txt  \n",
            "  inflating: stanford-corenlp-4.5.3/sutime/british.sutime.txt  \n",
            "  inflating: stanford-corenlp-4.5.3/input.txt.xml  \n",
            "  inflating: stanford-corenlp-4.5.3/javax.json-api-1.0-sources.jar  \n",
            "  inflating: stanford-corenlp-4.5.3/LICENSE.txt  \n",
            "  inflating: stanford-corenlp-4.5.3/jaxb-impl-2.4.0-b180830.0438-sources.jar  \n",
            "  inflating: stanford-corenlp-4.5.3/xom-1.3.8-sources.jar  \n",
            "  inflating: stanford-corenlp-4.5.3/Makefile  \n",
            "  inflating: stanford-corenlp-4.5.3/stanford-corenlp-4.5.3-sources.jar  \n",
            "  inflating: stanford-corenlp-4.5.3/slf4j-api.jar  \n",
            "  inflating: stanford-corenlp-4.5.3/jaxb-api-2.4.0-b180830.0359-sources.jar  \n",
            "  inflating: stanford-corenlp-4.5.3/jaxb-impl-2.4.0-b180830.0438.jar  \n",
            "  inflating: stanford-corenlp-4.5.3/pom.xml  \n",
            "  inflating: stanford-corenlp-4.5.3/joda-time-2.10.5-sources.jar  \n",
            "  inflating: stanford-corenlp-4.5.3/ejml-simple-0.39-sources.jar  \n",
            "  inflating: stanford-corenlp-4.5.3/ejml-ddense-0.39-sources.jar  \n",
            "  inflating: stanford-corenlp-4.5.3/joda-time.jar  \n",
            "  inflating: stanford-corenlp-4.5.3/istack-commons-runtime-3.0.7-sources.jar  \n",
            "  inflating: stanford-corenlp-4.5.3/StanfordCoreNlpDemo.java  \n",
            "  inflating: stanford-corenlp-4.5.3/jaxb-api-2.4.0-b180830.0359.jar  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget 'https://nlp.stanford.edu/software/stanford-corenlp-latest.zip'\n",
        "!unzip 'stanford-corenlp-latest.zip'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-dAKHb7QIpI",
        "outputId": "a899ee5c-e1bc-4720-96ab-176c577346bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-21 11:49:13--  https://nlp.stanford.edu/software/stanford-corenlp-latest.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: https://downloads.cs.stanford.edu/nlp/software/stanford-corenlp-latest.zip [following]\n",
            "--2023-03-21 11:49:14--  https://downloads.cs.stanford.edu/nlp/software/stanford-corenlp-latest.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2023-03-21 11:49:14 ERROR 404: Not Found.\n",
            "\n",
            "unzip:  cannot find or open stanford-corenlp-latest.zip, stanford-corenlp-latest.zip.zip or stanford-corenlp-latest.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stanfordcorenlp\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fw_7gV3pHJpQ",
        "outputId": "efacaff5-b572-4757-8b39-0fda69e65254"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting stanfordcorenlp\n",
            "  Downloading stanfordcorenlp-3.9.1.1-py2.py3-none-any.whl (5.7 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from stanfordcorenlp) (2.27.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from stanfordcorenlp) (5.9.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->stanfordcorenlp) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->stanfordcorenlp) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->stanfordcorenlp) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->stanfordcorenlp) (2.0.12)\n",
            "Installing collected packages: stanfordcorenlp\n",
            "Successfully installed stanfordcorenlp-3.9.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dependency parsing"
      ],
      "metadata": {
        "id": "njw19ohd-RLD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import stanfordcorenlp\n",
        "sc = stanfordcorenlp.StanfordCoreNLP('stanford-corenlp-4.5.3')"
      ],
      "metadata": {
        "id": "BVPPE8TePAxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I eat a lot of candy.\"\n",
        "dependencies = sc.dependency_parse(text)\n",
        "dependencies"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CAbPIuRQ2Hy",
        "outputId": "818fad49-65fc-4cef-d46f-3d2a97e51f80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('ROOT', 0, 2),\n",
              " ('nsubj', 2, 1),\n",
              " ('det', 4, 3),\n",
              " ('obj', 2, 4),\n",
              " ('case', 6, 5),\n",
              " ('nmod', 4, 6),\n",
              " ('punct', 2, 7)]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = nltk.word_tokenize(text)\n",
        "for (t, w1, w2) in dependencies:\n",
        "  if w1 < len(tokens) and w2 < len(tokens):\n",
        "    print(\"%s --> %s (%s)\" % (\n",
        "        tokens[w2-1] if w2>0 else \"\",\n",
        "        tokens[w1-1] if w1>0 else \"\",\n",
        "         t))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "fpkrxm6dZCeh",
        "outputId": "29f889a7-fa78-42fa-ca8b-a4f1ada70d68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-cf71d61e46ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdependencies\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mw1\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mw2\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     print(\"%s --> %s (%s)\" % (\n\u001b[1;32m      5\u001b[0m         \u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nltk' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Descriptions of dependency relations: https://universaldependencies.org/u/dep/\n",
        "\n",
        "Demo: https://nlp.stanford.edu/software/stanford-dependencies.html\n"
      ],
      "metadata": {
        "id": "a5u_0xRdfaP8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Constituent parsing"
      ],
      "metadata": {
        "id": "vwjQVOKv-NpC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parsed = sc.parse(text)\n",
        "print(parsed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwAAqvOFQ8Ff",
        "outputId": "bd7caa2a-3202-4364-d042-0ef63cf3baa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(ROOT\n",
            "  (S\n",
            "    (NP (PRP I))\n",
            "    (VP (VBP eat)\n",
            "      (NP\n",
            "        (NP (DT a) (NN lot))\n",
            "        (PP (IN of)\n",
            "          (NP (NN candy)))))\n",
            "    (. .)))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parsing with custom grammar"
      ],
      "metadata": {
        "id": "0NMLbkBIqrU8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.nltk.org/book/ch08.html"
      ],
      "metadata": {
        "id": "UHEZ0ie6t9Nq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "gram = nltk.CFG.fromstring(\"\"\"\n",
        "S -> NP VP | TO VB | VB\n",
        "VP -> V NP | V NP PP | V S | V PP\n",
        "PP -> P NP\n",
        "V -> \"caught\" | \"ate\" | \"likes\" | \"like\" | \"chase\" | \"go\" | \"fly\" | \"flies\" | \"eat\" | \"saw\"\n",
        "NP -> Det N | Det N PP | PRP\n",
        "Det -> \"the\" | \"a\" | \"an\" | \"my\" | \"some\" | \"The\"\n",
        "N -> \"mice\" | \"cat\" | \"dog\" |  \"school\" | \"Time\" | \"arrow\" | \"fly\" | \"flies\" | \"candy\" | \"man\" | \"park\"\n",
        "P -> \"in\" | \"to\" | \"on\"\n",
        "TO -> \"to\"\n",
        "PRP -> \"I\"  \"\"\")\n"
      ],
      "metadata": {
        "id": "RISdpyTPqv-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rdp = nltk.RecursiveDescentParser(gram)\n",
        "rdp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S--OvWijq10q",
        "outputId": "7ebbf5ba-6bda-46df-8ce0-365a5d7238d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<nltk.parse.recursivedescent.RecursiveDescentParser at 0x7efed3f50910>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I eat some candy\"\n",
        "for tree in rdp.parse(nltk.word_tokenize(text)):\n",
        "    print(tree)"
      ],
      "metadata": {
        "id": "Iu5HKnFhsyFG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddaae2ed-ebbf-4159-af91-e719978e7a92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S (NP (PRP I)) (VP (V eat) (NP (Det some) (N candy))))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Syntactic ambiguity:"
      ],
      "metadata": {
        "id": "ZKwCg4BgtCS9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "gram = nltk.CFG.fromstring(\"\"\"\n",
        "S -> NP VP | TO VB\n",
        "PP -> P NP\n",
        "V -> \"caught\" | \"ate\" | \"likes\" | \"like\" | \"chase\" | \"go\" | \"fly\" | \"flies\" | \"eat\" | \"saw\"\n",
        "NP -> Det N | Det N PP | PRP\n",
        "Det -> \"the\" | \"a\" | \"an\" | \"my\" | \"some\" | \"The\"\n",
        "N -> \"mice\" | \"cat\" | \"dog\" |  \"school\" | \"Time\" | \"arrow\" | \"fly\" | \"flies\" | \"candy\" | \"man\" | \"park\"\n",
        "P -> \"in\" | \"to\" | \"on\"\n",
        "TO -> \"to\"\n",
        "PRP -> \"I\"  \"\"\")"
      ],
      "metadata": {
        "id": "DJPT-XHtlLJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rdp = nltk.RecursiveDescentParser(gram, trace=2)\n",
        "rdp"
      ],
      "metadata": {
        "id": "7z9QRNU7vi4s",
        "outputId": "f33e04ab-917e-4be8-a345-ec79f6e2e268",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<nltk.parse.recursivedescent.RecursiveDescentParser at 0x7efed3ae89d0>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"The dog saw a man in the park\"\n",
        "for tree in rdp.parse(nltk.word_tokenize(text)):\n",
        "    print(tree)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-I8fOSo-szj_",
        "outputId": "63d4f593-c683-4dfc-f7b0-3ce73d57a305"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parsing 'The dog saw a man in the park'\n",
            "    [ * S ]\n",
            "  E [ * NP VP ]\n",
            "  E [ * Det N VP ]\n",
            "  E [ * 'the' N VP ]\n",
            "  E [ * 'a' N VP ]\n",
            "  E [ * 'an' N VP ]\n",
            "  E [ * 'my' N VP ]\n",
            "  E [ * 'some' N VP ]\n",
            "  E [ * 'The' N VP ]\n",
            "  M [ 'The' * N VP ]\n",
            "  E [ 'The' * 'mice' VP ]\n",
            "  E [ 'The' * 'cat' VP ]\n",
            "  E [ 'The' * 'dog' VP ]\n",
            "  M [ 'The' 'dog' * VP ]\n",
            "  E [ 'The' * 'school' VP ]\n",
            "  E [ 'The' * 'Time' VP ]\n",
            "  E [ 'The' * 'arrow' VP ]\n",
            "  E [ 'The' * 'fly' VP ]\n",
            "  E [ 'The' * 'flies' VP ]\n",
            "  E [ 'The' * 'candy' VP ]\n",
            "  E [ 'The' * 'man' VP ]\n",
            "  E [ 'The' * 'park' VP ]\n",
            "  E [ * Det N PP VP ]\n",
            "  E [ * 'the' N PP VP ]\n",
            "  E [ * 'a' N PP VP ]\n",
            "  E [ * 'an' N PP VP ]\n",
            "  E [ * 'my' N PP VP ]\n",
            "  E [ * 'some' N PP VP ]\n",
            "  E [ * 'The' N PP VP ]\n",
            "  M [ 'The' * N PP VP ]\n",
            "  E [ 'The' * 'mice' PP VP ]\n",
            "  E [ 'The' * 'cat' PP VP ]\n",
            "  E [ 'The' * 'dog' PP VP ]\n",
            "  M [ 'The' 'dog' * PP VP ]\n",
            "  E [ 'The' 'dog' * P NP VP ]\n",
            "  E [ 'The' 'dog' * 'in' NP VP ]\n",
            "  E [ 'The' 'dog' * 'to' NP VP ]\n",
            "  E [ 'The' 'dog' * 'on' NP VP ]\n",
            "  E [ 'The' * 'school' PP VP ]\n",
            "  E [ 'The' * 'Time' PP VP ]\n",
            "  E [ 'The' * 'arrow' PP VP ]\n",
            "  E [ 'The' * 'fly' PP VP ]\n",
            "  E [ 'The' * 'flies' PP VP ]\n",
            "  E [ 'The' * 'candy' PP VP ]\n",
            "  E [ 'The' * 'man' PP VP ]\n",
            "  E [ 'The' * 'park' PP VP ]\n",
            "  E [ * PRP VP ]\n",
            "  E [ * 'I' VP ]\n",
            "  E [ * TO VB ]\n",
            "  E [ * 'to' VB ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kq1zcNBwKhib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "srp = nltk.ShiftReduceParser(gram, trace=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8Djg8VwvSkI",
        "outputId": "38f036d5-7f9d-4aba-bd35-6b6fc525ff25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: V -> 'fly' will never be used\n",
            "Warning: V -> 'flies' will never be used\n",
            "Warning: P -> 'to' will never be used\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I like my candy\"\n",
        "for tree in srp.parse(nltk.word_tokenize(text)):\n",
        "    print(tree)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8YE9mlUvfxw",
        "outputId": "e6e79bce-3eb2-405a-ba53-9215f726a075"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parsing 'I like my candy'\n",
            "    [ * I like my candy]\n",
            "  S [ 'I' * like my candy]\n",
            "  R [ PRP * like my candy]\n",
            "  R [ NP * like my candy]\n",
            "  S [ NP 'like' * my candy]\n",
            "  R [ NP V * my candy]\n",
            "  S [ NP V 'my' * candy]\n",
            "  R [ NP V Det * candy]\n",
            "  S [ NP V Det 'candy' * ]\n",
            "  R [ NP V Det N * ]\n",
            "  R [ NP V NP * ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.draw.tree import draw_trees\n",
        "\n",
        "# (works locally)\n",
        "for tree in srp.parse(nltk.word_tokenize(text)):\n",
        "    draw_trees(tree)"
      ],
      "metadata": {
        "id": "2HPGpj0sKnf6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2eeb7f8-5c37-420d-a458-ed4324879f2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parsing 'I like my candy'\n",
            "    [ * I like my candy]\n",
            "  S [ 'I' * like my candy]\n",
            "  R [ PRP * like my candy]\n",
            "  R [ NP * like my candy]\n",
            "  S [ NP 'like' * my candy]\n",
            "  R [ NP V * my candy]\n",
            "  S [ NP V 'my' * candy]\n",
            "  R [ NP V Det * candy]\n",
            "  S [ NP V Det 'candy' * ]\n",
            "  R [ NP V Det N * ]\n",
            "  R [ NP V NP * ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "groucho_grammar = nltk.CFG.fromstring(\"\"\"\n",
        " S -> NP VP\n",
        " PP -> P NP\n",
        " NP -> Det N | Det N PP | 'I'\n",
        " VP -> V NP | VP PP\n",
        " Det -> 'an' | 'my'\n",
        " N -> 'elephant' | 'pajamas'\n",
        " V -> 'shot'\n",
        " P -> 'in'\n",
        " \"\"\")"
      ],
      "metadata": {
        "id": "BFfd-eRQy5Pl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent = ['I', 'shot', 'an', 'elephant', 'in', 'my', 'pajamas']\n",
        "parser = nltk.ChartParser(groucho_grammar)\n",
        "for tree in parser.parse(sent):\n",
        "  print(tree)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ggZ4VB4y-JL",
        "outputId": "505b4652-9a21-48b5-8099-bb5d309a6ad0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (NP I)\n",
            "  (VP\n",
            "    (VP (V shot) (NP (Det an) (N elephant)))\n",
            "    (PP (P in) (NP (Det my) (N pajamas)))))\n",
            "(S\n",
            "  (NP I)\n",
            "  (VP\n",
            "    (V shot)\n",
            "    (NP (Det an) (N elephant) (PP (P in) (NP (Det my) (N pajamas))))))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent = ['I', 'shot', 'an', 'elephant', 'in', 'my', 'pajamas']\n",
        "parser = nltk.ShiftReduceParser(groucho_grammar)\n",
        "for tree in parser.parse(sent):\n",
        "  print(tree)"
      ],
      "metadata": {
        "id": "zeVp4k5volVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercitii (1p total)"
      ],
      "metadata": {
        "id": "H_1O3gu1A-Ax"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Completati functia scrisa in laboratorul interior cu POS-tagging: in final veti avea o functie care sa primeasca un text si sa faca toata preprocesarea (tokenizare, lematizare, normalizare) si pos-tagging, si sa intoarca textul cu tags pe cuvinte.\n",
        "\n",
        "/\n",
        "\n",
        "Add to the function implemented for the past lab instructions for POS-tagging: in the end you should have a function which receives an input text and performs preprocessing from beginning to end (tokenization, lemmatization, normalization) as well as POS-tagging, then returns the tagged text."
      ],
      "metadata": {
        "id": "wB4FM4LABFAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install num2words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULiTr0SULBQG",
        "outputId": "5aeeec20-40c7-4c59-a3a4-ef29a6996ada"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting num2words\n",
            "  Downloading num2words-0.5.12-py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 KB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docopt>=0.6.2\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: docopt\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13721 sha256=2cbfc0256d8d343b4e46529f160bbef14699125f75bb53e2a9948e2fb78dd238\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/4a/46/1309fc853b8d395e60bafaf1b6df7845bdd82c95fd59dd8d2b\n",
            "Successfully built docopt\n",
            "Installing collected packages: docopt, num2words\n",
            "Successfully installed docopt-0.6.2 num2words-0.5.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "from num2words import num2words\n",
        "from nltk import pos_tag"
      ],
      "metadata": {
        "id": "S6WyYBjQI1ft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAbhj05pJoa6",
        "outputId": "081cfe16-a2db-4240-ad60-dd9f59fd25ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text, remove_punctuation=True, lowercase=True, numbers_to_words_or_remove=None, remove_stopwords=False, stemmer=None, lemmatizer=None, pos_tagging=False):\n",
        "  if remove_punctuation:\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "  if lowercase:\n",
        "    text = text.lower()\n",
        "\n",
        "  if numbers_to_words_or_remove == \"remove\":\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "\n",
        "  if numbers_to_words_or_remove == \"words\":\n",
        "    digits = re.findall(r'\\d+', text)\n",
        "    for digit in digits:\n",
        "        word = num2words(int(digit))\n",
        "        text = text.replace(digit, word)\n",
        "\n",
        "  tokens = word_tokenize(text)\n",
        "\n",
        "  if remove_stopwords:\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [token for token in tokens if not token in stop_words]\n",
        "\n",
        "  if stemmer:\n",
        "    stemmer = PorterStemmer()\n",
        "    tokens = [stemmer.stem(token) for token in tokens]\n",
        "\n",
        "  if lemmatizer:\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "  if pos_tagging:\n",
        "    tokens = pos_tag(tokens)\n",
        "\n",
        "  return tokens"
      ],
      "metadata": {
        "id": "A2oUgHnkJqPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news = \"\"\"Biden warns Putin over Ukraine: 'There will be strong economic consequences'\n",
        "US President Joe Biden has warned his Russian counterpart Vladimir Putin that there will be \"strong economic consequences\" if Russia invades Ukraine.\n",
        "Speaking to reporters at the White House, Mr Biden also said he hoped for a peaceful outcome to the crisis.\n",
        "The US and its allies have accused Russia of building up troops and military hardware close to Ukraine's borders.\n",
        "Moscow has denied planning an invasion, but says it reserves the right to move its forces around its territory.\n",
        "Tensions between Russia and Ukraine have been high since 2014, when Russia annexed Ukraine's Crimean peninsula and pro-Russian separatists seized control of parts of Ukraine's Donetsk and Luhansk regions.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "mkCPvJ4XCCU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Aplicati functia pe un fragment de cateva sute de cuvinte din stiri din ultimele cateva zile (aveti grija sa fie intr-o limba pe care functia o suporta). Afisati distributia partilor de vorbire intr-un grafic.\n",
        "\n",
        "/\n",
        "\n",
        "Execute your function on a piece of news from the past days of at least a few hundred words (make sure it's in a language that the function supports). Illustrate the distribution of POSs in a graph."
      ],
      "metadata": {
        "id": "jb70NTXABV2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "import seaborn as sns\n",
        "sns.set_theme()\n",
        "\n",
        "tagged_text = preprocess(news, remove_punctuation=True, lowercase=True,  numbers_to_words_or_remove='remove', remove_stopwords=False, stemmer=None, lemmatizer=None, pos_tagging=True)\n",
        "\n",
        "print(tagged_text)\n",
        "\n",
        "tags = [tag for token, tag in tagged_text]\n",
        "freq = Counter(tags)\n",
        "\n",
        "fig = plt.figure(figsize = (17, 7))\n",
        "plt.bar(freq.keys(), freq.values())\n",
        "plt.xlabel(\"POS tags\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "zVcdoht_LbHi",
        "outputId": "16bdb1b8-712f-43b6-92ed-3fbb8c82b572"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('biden', 'NN'), ('warns', 'NNS'), ('putin', 'NN'), ('over', 'IN'), ('ukraine', 'JJ'), ('there', 'EX'), ('will', 'MD'), ('be', 'VB'), ('strong', 'JJ'), ('economic', 'JJ'), ('consequences', 'NNS'), ('us', 'PRP'), ('president', 'NN'), ('joe', 'NN'), ('biden', 'NN'), ('has', 'VBZ'), ('warned', 'VBN'), ('his', 'PRP$'), ('russian', 'JJ'), ('counterpart', 'NN'), ('vladimir', 'NN'), ('putin', 'NN'), ('that', 'IN'), ('there', 'EX'), ('will', 'MD'), ('be', 'VB'), ('strong', 'JJ'), ('economic', 'JJ'), ('consequences', 'NNS'), ('if', 'IN'), ('russia', 'JJ'), ('invades', 'NNS'), ('ukraine', 'JJ'), ('speaking', 'VBG'), ('to', 'TO'), ('reporters', 'NNS'), ('at', 'IN'), ('the', 'DT'), ('white', 'JJ'), ('house', 'NN'), ('mr', 'NN'), ('biden', 'NN'), ('also', 'RB'), ('said', 'VBD'), ('he', 'PRP'), ('hoped', 'VBD'), ('for', 'IN'), ('a', 'DT'), ('peaceful', 'JJ'), ('outcome', 'NN'), ('to', 'TO'), ('the', 'DT'), ('crisis', 'NN'), ('the', 'DT'), ('us', 'PRP'), ('and', 'CC'), ('its', 'PRP$'), ('allies', 'NNS'), ('have', 'VBP'), ('accused', 'VBN'), ('russia', 'NN'), ('of', 'IN'), ('building', 'VBG'), ('up', 'RP'), ('troops', 'NNS'), ('and', 'CC'), ('military', 'JJ'), ('hardware', 'NN'), ('close', 'RB'), ('to', 'TO'), ('ukraines', 'NNS'), ('borders', 'NNS'), ('moscow', 'VBP'), ('has', 'VBZ'), ('denied', 'VBN'), ('planning', 'VBG'), ('an', 'DT'), ('invasion', 'NN'), ('but', 'CC'), ('says', 'VBZ'), ('it', 'PRP'), ('reserves', 'NNS'), ('the', 'DT'), ('right', 'NN'), ('to', 'TO'), ('move', 'VB'), ('its', 'PRP$'), ('forces', 'NNS'), ('around', 'IN'), ('its', 'PRP$'), ('territory', 'NN'), ('tensions', 'NNS'), ('between', 'IN'), ('russia', 'NN'), ('and', 'CC'), ('ukraine', 'NN'), ('have', 'VBP'), ('been', 'VBN'), ('high', 'JJ'), ('since', 'IN'), ('when', 'WRB'), ('russia', 'NN'), ('annexed', 'VBD'), ('ukraines', 'JJ'), ('crimean', 'JJ'), ('peninsula', 'NN'), ('and', 'CC'), ('prorussian', 'JJ'), ('separatists', 'NNS'), ('seized', 'VBD'), ('control', 'NN'), ('of', 'IN'), ('parts', 'NNS'), ('of', 'IN'), ('ukraines', 'NNS'), ('donetsk', 'NNS'), ('and', 'CC'), ('luhansk', 'JJ'), ('regions', 'NNS')]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1224x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Modificati functia de mai sus astfel incat sa efectueze POS-tagging inainte sau dupa lematizare. Comparati diferentele. Afisati cuvintele (top 20) pentru care POS tag-ul identificat difera cel mai des intre cele doua versiuni.\n",
        "\n",
        "/\n",
        "\n",
        "Modify your function such that POS-tagging is performed before or after lemmatization. Print the words in the vocabulary (top 20) for which the identified POS tag differs most often between the two versions."
      ],
      "metadata": {
        "id": "sxDdel9eCYan"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_2(text, remove_punctuation=True, lowercase=True, numbers_to_words_or_remove=None, remove_stopwords=False, stemmer=None, lemmatizer=None):\n",
        "  if remove_punctuation:\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "  if lowercase:\n",
        "    text = text.lower()\n",
        "\n",
        "  if numbers_to_words_or_remove == \"remove\":\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "\n",
        "  if numbers_to_words_or_remove == \"words\":\n",
        "    digits = re.findall(r'\\d+', text)\n",
        "    for digit in digits:\n",
        "        word = num2words(int(digit))\n",
        "        text = text.replace(digit, word)\n",
        "\n",
        "  tokens = word_tokenize(text)\n",
        "\n",
        "  if remove_stopwords:\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [token for token in tokens if not token in stop_words]\n",
        "\n",
        "  if stemmer:\n",
        "    stemmer = PorterStemmer()\n",
        "    tokens = [stemmer.stem(token) for token in tokens]\n",
        "\n",
        "  if lemmatizer == \"before\":\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tagged_tokens = pos_tag(tokens)\n",
        "    tagged_lemmas = []\n",
        "    for token, tag in tagged_tokens:\n",
        "      lemma = lemmatizer.lemmatize(token)\n",
        "      tagged_lemmas.append((lemma, tag))\n",
        "    return tagged_lemmas\n",
        "\n",
        "  elif lemmatizer == \"after\":\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    tagged_tokens = pos_tag(tokens)\n",
        "    return tagged_tokens\n",
        "\n",
        "  return tokens"
      ],
      "metadata": {
        "id": "naOAjOjFb2Y4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tagged_text_before = preprocess_2(news, remove_punctuation=True, lowercase=True,  numbers_to_words_or_remove='remove', remove_stopwords=False, stemmer=None, lemmatizer=\"before\")\n",
        "tagged_text_after = preprocess_2(news, remove_punctuation=True, lowercase=True,  numbers_to_words_or_remove='remove', remove_stopwords=False, stemmer=None, lemmatizer=\"after\")\n"
      ],
      "metadata": {
        "id": "N3rtFMFwUEf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(tagged_text_before))\n",
        "print(len(tagged_text_after))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOr8V0-YVFay",
        "outputId": "6468f7f0-7c06-4c03-e8da-3c83e685cb2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "119\n",
            "119\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for a, b in zip(tagged_text_before, tagged_text_after):\n",
        "  if a != b:\n",
        "    print(a, b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQpiXiXicZRI",
        "outputId": "190f1b0d-c4f6-456f-8599-5c410f8434cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('consequence', 'NNS') ('consequence', 'NN')\n",
            "('u', 'PRP') ('u', 'JJ')\n",
            "('ha', 'VBZ') ('ha', 'NN')\n",
            "('warned', 'VBN') ('warned', 'VBD')\n",
            "('consequence', 'NNS') ('consequence', 'NN')\n",
            "('reporter', 'NNS') ('reporter', 'VB')\n",
            "('u', 'PRP') ('u', 'NN')\n",
            "('it', 'PRP$') ('it', 'PRP')\n",
            "('ally', 'NNS') ('ally', 'RB')\n",
            "('troop', 'NNS') ('troop', 'NN')\n",
            "('ukraine', 'NNS') ('ukraine', 'VB')\n",
            "('border', 'NNS') ('border', 'NN')\n",
            "('moscow', 'VBP') ('moscow', 'NN')\n",
            "('ha', 'VBZ') ('ha', 'NN')\n",
            "('denied', 'VBN') ('denied', 'VBD')\n",
            "('say', 'VBZ') ('say', 'VBP')\n",
            "('reserve', 'NNS') ('reserve', 'VBZ')\n",
            "('it', 'PRP$') ('it', 'PRP')\n",
            "('force', 'NNS') ('force', 'NN')\n",
            "('it', 'PRP$') ('it', 'PRP')\n",
            "('territory', 'NN') ('territory', 'JJ')\n",
            "('tension', 'NNS') ('tension', 'NN')\n",
            "('separatist', 'NNS') ('separatist', 'NN')\n",
            "('part', 'NNS') ('part', 'NN')\n",
            "('ukraine', 'NNS') ('ukraine', 'JJ')\n",
            "('donetsk', 'NNS') ('donetsk', 'NN')\n",
            "('region', 'NNS') ('region', 'NN')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Gasiti bigramele de POS tags cele mai frecvente in textul analizat, si apoi in propozitiile tagged din Brown corpus.\n",
        "\n",
        "/\n",
        "\n",
        "Find the most frequent POS tag bigrams occurring in the analyzed text, then in the tagged sentences in the Brown corpus."
      ],
      "metadata": {
        "id": "w7H6Dwdcb2qq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import bigrams, FreqDist\n",
        "\n",
        "tokens = nltk.word_tokenize(news)\n",
        "tagged_tokens = nltk.pos_tag(tokens)\n",
        "bigram_freq = FreqDist(list(bigrams(tags)))\n",
        "print(bigram_freq.most_common(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfXwb8wjeYIJ",
        "outputId": "220fa913-2aac-49f7-b359-9cec504254c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(('NN', 'NN'), 6), (('JJ', 'NNS'), 5), (('JJ', 'NN'), 5), (('NNS', 'IN'), 5), (('NN', 'IN'), 4), (('JJ', 'JJ'), 3), (('DT', 'NN'), 3), (('CC', 'JJ'), 3), (('NN', 'CC'), 3), (('NN', 'NNS'), 2)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('brown')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S60H_7-Ihnti",
        "outputId": "87eac5dd-5bdd-42b8-fd75-b39486df302d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import brown\n",
        "tagged_sentences = brown.tagged_sents()\n",
        "bigrams = Counter([bigram for sentence in tagged_sentences for bigram in nltk.bigrams(tag for _, tag in sentence)])\n",
        "print(bigrams.most_common(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ier11bmmfjSK",
        "outputId": "4a4ac4d6-bfe6-45b1-a30b-834c101d907c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(('AT', 'NN'), 48372), (('IN', 'AT'), 43271), (('NN', 'IN'), 42252), (('JJ', 'NN'), 28407), (('NN', '.'), 19857), (('AT', 'JJ'), 19487), (('NN', ','), 18279), (('IN', 'NN'), 17225), (('NNS', 'IN'), 14504), (('TO', 'VB'), 12291)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Write a grammar and code to produce two trees, one for each reading of the phrase \"old men and women\""
      ],
      "metadata": {
        "id": "cQ9ez4eHqcx_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grammar = nltk.CFG.fromstring(\"\"\"\n",
        "    S -> NP Conj NP\n",
        "    NP -> Adj N | Adj NP | Det N | Det Adj N\n",
        "    Adj -> 'old'\n",
        "    N -> 'men' | 'women'\n",
        "    Conj -> 'and'\n",
        "    Det -> 'the'\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "8hR_PQ-Zjyp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent = [\"old\", \"men\", \"and\", \"women\"]\n",
        "parser = nltk.ChartParser(grammar)\n",
        "for tree in list(parser.parse(sent)):\n",
        "  print(tree)"
      ],
      "metadata": {
        "id": "QWRZlw_6rcFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mini-proiect / Homework (+3p)"
      ],
      "metadata": {
        "id": "QNyFLIXOBBPS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(v PDF separat)"
      ],
      "metadata": {
        "id": "2mdpLayrE-WC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WsqHgU4zAZdM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}